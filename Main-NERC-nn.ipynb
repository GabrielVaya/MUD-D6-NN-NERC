{"cells":[{"cell_type":"markdown","metadata":{"id":"TEZjmE1vglrx"},"source":["# Name Entity Recognition using Deep Learning\n","\n","* Upload the lab_resources and NERC_nn files to you Drive Account:\n","  * Lab_resource: https://www.cs.upc.edu/~turmo/mud/lab/lab_resources.zip\n","  * NERC_nn code: https://www.cs.upc.edu/~turmo/mud/lab/06-NERC-nn.zip\n","  \n","* Before running the code, ensure that your Google Colab is set to use GPU:\n","  * Edit → Notebook Settings\n","* Mount your Drive disk unit:\n","  * Left-side menu → Files → Mount drive (the icon that looks like a folder with the Drive logo).\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29994,"status":"ok","timestamp":1717942487388,"user":{"displayName":"Gaby Regla","userId":"07883863642306501446"},"user_tz":-120},"id":"sWlOV35mOwem","outputId":"0461cd8f-375e-4bc4-f198-58731d7a728d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"BLzeoFyGgw9E"},"source":["Define the paths to the data and utils in your Drive unit:"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1717942487388,"user":{"displayName":"Gaby Regla","userId":"07883863642306501446"},"user_tz":-120},"id":"0xgFDKnLhNbj"},"outputs":[],"source":["import os\n","utilsdir='/content/drive/MyDrive/06-NERC-nn 2/'"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1717942487388,"user":{"displayName":"Gaby Regla","userId":"07883863642306501446"},"user_tz":-120},"id":"HG-oHsOjfnDo"},"outputs":[],"source":["evaluatordir= os.path.join(utilsdir,'util/')\n","traindir=os.path.join(utilsdir,'data/train')\n","validationdir=os.path.join(utilsdir,'data/devel')\n","testdir=os.path.join(utilsdir,'data/test')\n","pretrained_model=os.path.join(utilsdir,'GoogleNews-vectors-negative300.bin')\n","modelname ='model'\n","outfile ='out.txt'"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6664,"status":"ok","timestamp":1717942494048,"user":{"displayName":"Gaby Regla","userId":"07883863642306501446"},"user_tz":-120},"id":"bqFrxX6SB9cr","outputId":"de5eed8a-e6a6-4ea2-ddb1-4ee17bafaad0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/611.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n","Collecting typeguard\u003c3.0.0,\u003e=2.7 (from tensorflow-addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow-addons\n","Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"]}],"source":["!pip install tensorflow-addons\n","import sys\n","sys.path.insert(1,utilsdir) # Path to the utils folder on your Google Drive disk\n","sys.path.insert(1,evaluatordir) # Path to the evaluator folder on your Google Drive disk"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8732,"status":"ok","timestamp":1717942502773,"user":{"displayName":"Gaby Regla","userId":"07883863642306501446"},"user_tz":-120},"id":"CuIdfFDlA9Q9","outputId":"73ebe57f-bf24-496c-a791-d84a6ca6c8c8"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from contextlib import redirect_stdout\n","\n","from tensorflow.keras import Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import LSTM, GRU, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, concatenate, Softmax\n","#from tensorflow_addons.text.crf_wrapper import CRFModelWrapper\n","\n","\n","#from codemaps_sufpref import *\n","#from codemaps_lc import *\n","#from codemaps_lcpos import *\n","#from codemaps_posNOlc import *\n","#from codemaps_NOlc_pos_len import *\n","#from codemaps_NOlc_pos_len_pct import *\n","#from codemaps_NOlc_pos_len_NOpct_cap import *\n","from codemaps_NOlc_pos_len_pct_caps_sufpref2 import *\n","\n","import nltk\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1717942502773,"user":{"displayName":"Gaby Regla","userId":"07883863642306501446"},"user_tz":-120},"id":"RKB3K2EMrQzn"},"outputs":[],"source":["import random\n","import numpy as np\n","import tensorflow as tf\n","import os\n","random.seed(42)\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","os.environ['PYTHONHASHSEED'] = '0'"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1444364,"status":"ok","timestamp":1717943947131,"user":{"displayName":"Gaby Regla","userId":"07883863642306501446"},"user_tz":-120},"id":"IYS_dDVXj2me","outputId":"83e73310-e986-49cb-9613-8c35cc6acf8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[==================================================] 100.0% 376.1/376.1MB downloaded\n"]}],"source":["import gensim.downloader as api\n","from gensim.models import KeyedVectors\n","\n","# Load Google News pre-trained word2vec embeddings\n","#word2vec_model = KeyedVectors.load_word2vec_format(pretrained_model, binary=True)\n","\n","\n","# Download the GloVe model\n","glove_model = api.load('glove-wiki-gigaword-300')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1717943947132,"user":{"displayName":"Gaby Regla","userId":"07883863642306501446"},"user_tz":-120},"id":"BGAayvnqjo10"},"outputs":[],"source":["def create_embedding_matrix(word_index, pretrained_model, embedding_dim=300):\n","    embedding_matrix = np.zeros((len(word_index), embedding_dim))\n","    for word, i in word_index.items():\n","        try:\n","            embedding_vector = pretrained_model[word]\n","            embedding_matrix[i] = embedding_vector\n","        except KeyError:\n","            pass  # Words not found in the embedding index will be all-zeros.\n","    return embedding_matrix"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1717943947132,"user":{"displayName":"Gaby Regla","userId":"07883863642306501446"},"user_tz":-120},"id":"D7t-xqv7BMX8"},"outputs":[],"source":["def build_network(codes) :\n","\n","   word_index = codes.word_index\n","   # Create embedding matrix from pre-trained embeddings\n","   #embedding_matrix = create_embedding_matrix(word_index, word2vec_model, embedding_dim=300)\n","   embedding_matrix = create_embedding_matrix(word_index, glove_model, embedding_dim=300)\n","\n","   # sizes\n","   n_words = codes.get_n_words()\n","   n_sufs = codes.get_n_sufs()\n","   n_prefs = codes.get_n_prefs()\n","   n_sufs2 = codes.get_n_sufs2()\n","   n_prefs2 = codes.get_n_prefs2()\n","   #n_lc_words = codes.get_n_lc_words()\n","   n_pos = codes.get_n_pos()\n","   n_len = codes.get_n_len()\n","   n_punct = codes.get_n_punct()\n","   n_caps = codes.get_n_cap()\n","   n_labels = codes.get_n_labels()\n","   max_len = codes.maxlen\n","\n","\n","   #####################################################\n","   # word embeddings pretrained model\n","   inptW = Input(shape=(max_len,))\n","   embW = Embedding(input_dim=n_words, output_dim=300, weights=[embedding_matrix],\n","                      input_length=max_len, mask_zero=False)(inptW)\n","   embW = Dropout(0.1)(embW)\n","\n","   '''# word embeddings\n","   inptW = Input(shape=(max_len,))\n","   embW = Embedding(input_dim=n_words, output_dim=200,\n","                      input_length=max_len, mask_zero=False)(inptW)\n","   embW = Dropout(0.1)(embW)'''\n","\n","   # suf embeddings\n","   inptS = Input(shape=(max_len,))\n","   embS = Embedding(input_dim=n_sufs, output_dim=200,\n","                      input_length=max_len, mask_zero=False)(inptS)\n","   embS = Dropout(0.1)(embS)\n","\n","   # pref embeddings\n","   inptP = Input(shape=(max_len,))\n","   embP = Embedding(input_dim=n_prefs, output_dim=200,\n","                      input_length=max_len, mask_zero=False)(inptP)\n","   embP = Dropout(0.1)(embP)\n","\n","   # suf embeddings\n","   inptS2 = Input(shape=(max_len,))\n","   embS2 = Embedding(input_dim=n_sufs2, output_dim=200,\n","                      input_length=max_len, mask_zero=False)(inptS2)\n","   embS2 = Dropout(0.1)(embS2)\n","\n","   # pref embeddings\n","   inptP2 = Input(shape=(max_len,))\n","   embP2 = Embedding(input_dim=n_prefs2, output_dim=200,\n","                      input_length=max_len, mask_zero=False)(inptP2)\n","   embP2 = Dropout(0.1)(embP2)\n","\n","   '''lc_index = codes.lc_index\n","   # Create embedding matrix from pre-trained embeddings\n","   #embedding_matrix = create_embedding_matrix(word_index, govel_model, embedding_dim=300)\n","   embedding_matrix_lc = create_embedding_matrix(lc_index, word2vec_model, embedding_dim=300)\n","\n","   # lc embeddings pretrained model\n","   inptLC = Input(shape=(max_len,))\n","   embLC = Embedding(input_dim=n_lc_words, output_dim=300, weights=[embedding_matrix_lc],\n","                      input_length=max_len, mask_zero=False)(inptLC)\n","   embLC = Dropout(0.1)(embLC)'''\n","\n","   '''# lc embeddings\n","   inptLC = Input(shape=(max_len,))\n","   embLC = Embedding(input_dim=n_lc_words, output_dim=200,\n","                      input_length=max_len, mask_zero=False)(inptLC)\n","   embLC = Dropout(0.1)(embLC)'''\n","\n","   # postags embeddings\n","   inptPOS = Input(shape=(max_len,))\n","   embPOS = Embedding(input_dim=n_pos, output_dim=200,\n","                      input_length=max_len, mask_zero=False)(inptPOS)\n","   embPOS = Dropout(0.1)(embPOS)\n","\n","   # lenths embeddings\n","   inptLen = Input(shape=(max_len,))\n","   embLen = Embedding(input_dim=n_len, output_dim=200,\n","                      input_length=max_len, mask_zero=False)(inptLen)\n","   embLen = Dropout(0.1)(embLen)\n","\n","   # punctuation embeddings\n","   inptPct = Input(shape=(max_len,))\n","   embPct = Embedding(input_dim=n_punct, output_dim=200,\n","                      input_length=max_len, mask_zero=False)(inptPct)\n","   embPct = Dropout(0.1)(embPct)\n","\n","   # caps embeddings\n","   inptCap = Input(shape=(max_len,))\n","   embCap = Embedding(input_dim=n_caps, output_dim=200,\n","                      input_length=max_len, mask_zero=False)(inptCap)\n","   embCap = Dropout(0.1)(embCap)\n","\n","   ########################################################\n","   # model concatenation\n","   #model = concatenate([embW,embS,embP])\n","   #model = concatenate([embW,embS,embP,embLC])\n","   #model = concatenate([embW,embS,embP,embLC,embPOS])\n","   #model = concatenate([embW,embS,embP,embPOS])\n","   #model = concatenate([embW,embS,embP,embPOS,embLen])\n","   #model = concatenate([embW,embS,embP,embPOS,embLen,embPct])\n","   #model = concatenate([embW,embS,embP,embPOS,embLen,embPct,embCap])\n","   #model = concatenate([embW,embS,embP,embPOS,embLen,embCap])\n","   model = concatenate([embW,embS,embP,embS2,embP2,embPOS,embLen,embPct,embCap])\n","\n","   y = Bidirectional(LSTM(units=500, return_sequences=True))(model)  #  biLSTM\n","   out = TimeDistributed(Dense(n_labels, activation=Softmax()))(y)\n","\n","   return Model(\n","        #inputs=[inptW,inptS,inptP], outputs=out\n","        #inputs=[inptW,inptS,inptP,inptLC], outputs=out\n","        #inputs=[inptW,inptS,inptP,inptLC,inptPOS], outputs=out\n","        #inputs=[inptW,inptS,inptP,inptPOS], outputs=out\n","        #inputs=[inptW,inptS,inptP,inptPOS,inptLen], outputs=out\n","        #inputs=[inptW,inptS,inptP,inptPOS,inptLen,inptPct], outputs=out\n","        #inputs=[inptW,inptS,inptP,inptPOS,inptLen,inptPct,inptCap], outputs=out\n","        #inputs=[inptW,inptS,inptP,inptPOS,inptLen,inptCap], outputs=out\n","        inputs=[inptW,inptS,inptP,inptS2,inptP2,inptPOS,inptLen,inptPct,inptCap], outputs=out\n","\n","    )\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":22400,"status":"ok","timestamp":1717944783870,"user":{"displayName":"Gaby Regla","userId":"07883863642306501446"},"user_tz":-120},"id":"AGCB28e0pZHR"},"outputs":[],"source":["\n","\n","# load train and validation data\n","traindata = Dataset(traindir)\n","valdata = Dataset(validationdir)\n","\n","# create indexes from training data\n","max_len = 300 ##\n","suf_len = 3 ##\n","pref_len = 3 ##\n","suf_len2 = 4 ##\n","pref_len2 = 5 ##\n","codes  = Codemaps(traindata, max_len, suf_len, pref_len, suf_len2, pref_len2)\n","\n","# encode datasets\n","#[Xt,Xts,Xtp] = codes.encode_words(traindata)\n","#[Xt,Xts,Xtp,Xtlc] = codes.encode_words(traindata)\n","#[Xt,Xts,Xtp,Xtlc,Xtpos] = codes.encode_words(traindata)\n","#[Xt,Xts,Xtp,Xtpos] = codes.encode_words(traindata)\n","#[Xt,Xts,Xtp,Xtpos,Xtlen] = codes.encode_words(traindata)\n","#[Xt,Xts,Xtp,Xtpos,Xtlen,Xtpct] = codes.encode_words(traindata)\n","#[Xt,Xts,Xtp,Xtpos,Xtlen,Xtpct,Xtcap] = codes.encode_words(traindata)\n","#[Xt,Xts,Xtp,Xtpos,Xtlen,Xtcap] = codes.encode_words(traindata)\n","[Xt,Xts,Xtp,Xts2,Xtp2,Xtpos,Xtlen,Xtpct,Xtcap] = codes.encode_words(traindata)\n","\n","Yt = codes.encode_labels(traindata)\n","\n","#[Xv,Xvs,Xvp] = codes.encode_words(valdata)\n","#[Xv,Xvs,Xvp,Xvlc] = codes.encode_words(valdata)\n","#[Xv,Xvs,Xvp,Xvlc,Xvpos] = codes.encode_words(valdata)\n","#[Xv,Xvs,Xvp,Xvpos] = codes.encode_words(valdata)\n","#[Xv,Xvs,Xvp,Xvpos,Xvlen] = codes.encode_words(valdata)\n","#[Xv,Xvs,Xvp,Xvpos,Xvlen,Xvpct] = codes.encode_words(valdata)\n","#[Xv,Xvs,Xvp,Xvpos,Xvlen,Xvpct,Xvcap] = codes.encode_words(valdata)\n","#[Xv,Xvs,Xvp,Xvpos,Xvlen,Xvcap] = codes.encode_words(valdata)\n","[Xv,Xvs,Xvp,Xvs2,Xvp2,Xvpos,Xvlen,Xvpct,Xvcap] = codes.encode_words(valdata)\n","Yv = codes.encode_labels(valdata)\n","\n","n_tags = codes.get_n_labels()\n","max_len = codes.maxlen"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1302,"status":"ok","timestamp":1717944785155,"user":{"displayName":"Gaby Regla","userId":"07883863642306501446"},"user_tz":-120},"id":"l6jXPIjLDTcm","outputId":"5e7e960e-8dff-493a-c6fd-241f00fd91ad"},"outputs":[{"name":"stderr","output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_10 (InputLayer)       [(None, 300)]                0         []                            \n","                                                                                                  \n"," input_11 (InputLayer)       [(None, 300)]                0         []                            \n","                                                                                                  \n"," input_12 (InputLayer)       [(None, 300)]                0         []                            \n","                                                                                                  \n"," input_13 (InputLayer)       [(None, 300)]                0         []                            \n","                                                                                                  \n"," input_14 (InputLayer)       [(None, 300)]                0         []                            \n","                                                                                                  \n"," input_15 (InputLayer)       [(None, 300)]                0         []                            \n","                                                                                                  \n"," input_16 (InputLayer)       [(None, 300)]                0         []                            \n","                                                                                                  \n"," input_17 (InputLayer)       [(None, 300)]                0         []                            \n","                                                                                                  \n"," input_18 (InputLayer)       [(None, 300)]                0         []                            \n","                                                                                                  \n"," embedding_9 (Embedding)     (None, 300, 300)             2902800   ['input_10[0][0]']            \n","                                                                                                  \n"," embedding_10 (Embedding)    (None, 300, 200)             386600    ['input_11[0][0]']            \n","                                                                                                  \n"," embedding_11 (Embedding)    (None, 300, 200)             386600    ['input_12[0][0]']            \n","                                                                                                  \n"," embedding_12 (Embedding)    (None, 300, 200)             699200    ['input_13[0][0]']            \n","                                                                                                  \n"," embedding_13 (Embedding)    (None, 300, 200)             991400    ['input_14[0][0]']            \n","                                                                                                  \n"," embedding_14 (Embedding)    (None, 300, 200)             9200      ['input_15[0][0]']            \n","                                                                                                  \n"," embedding_15 (Embedding)    (None, 300, 200)             8200      ['input_16[0][0]']            \n","                                                                                                  \n"," embedding_16 (Embedding)    (None, 300, 200)             800       ['input_17[0][0]']            \n","                                                                                                  \n"," embedding_17 (Embedding)    (None, 300, 200)             800       ['input_18[0][0]']            \n","                                                                                                  \n"," dropout_9 (Dropout)         (None, 300, 300)             0         ['embedding_9[0][0]']         \n","                                                                                                  \n"," dropout_10 (Dropout)        (None, 300, 200)             0         ['embedding_10[0][0]']        \n","                                                                                                  \n"," dropout_11 (Dropout)        (None, 300, 200)             0         ['embedding_11[0][0]']        \n","                                                                                                  \n"," dropout_12 (Dropout)        (None, 300, 200)             0         ['embedding_12[0][0]']        \n","                                                                                                  \n"," dropout_13 (Dropout)        (None, 300, 200)             0         ['embedding_13[0][0]']        \n","                                                                                                  \n"," dropout_14 (Dropout)        (None, 300, 200)             0         ['embedding_14[0][0]']        \n","                                                                                                  \n"," dropout_15 (Dropout)        (None, 300, 200)             0         ['embedding_15[0][0]']        \n","                                                                                                  \n"," dropout_16 (Dropout)        (None, 300, 200)             0         ['embedding_16[0][0]']        \n","                                                                                                  \n"," dropout_17 (Dropout)        (None, 300, 200)             0         ['embedding_17[0][0]']        \n","                                                                                                  \n"," concatenate_1 (Concatenate  (None, 300, 1900)            0         ['dropout_9[0][0]',           \n"," )                                                                   'dropout_10[0][0]',          \n","                                                                     'dropout_11[0][0]',          \n","                                                                     'dropout_12[0][0]',          \n","                                                                     'dropout_13[0][0]',          \n","                                                                     'dropout_14[0][0]',          \n","                                                                     'dropout_15[0][0]',          \n","                                                                     'dropout_16[0][0]',          \n","                                                                     'dropout_17[0][0]']          \n","                                                                                                  \n"," bidirectional_1 (Bidirecti  (None, 300, 1000)            9604000   ['concatenate_1[0][0]']       \n"," onal)                                                                                            \n","                                                                                                  \n"," time_distributed_1 (TimeDi  (None, 300, 10)              10010     ['bidirectional_1[0][0]']     \n"," stributed)                                                                                       \n","                                                                                                  \n","==================================================================================================\n","Total params: 14999610 (57.22 MB)\n","Trainable params: 14999610 (57.22 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["model = build_network(codes)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","#optimizer = tf.keras.optimizers.Nadam(learning_rate=0.002)\n","\n","model.compile(optimizer=optimizer ,metrics=[\"accuracy\"], loss=\"sparse_categorical_crossentropy\")\n","model.build([(None,max_len),(None,max_len),(None,max_len),(None,max_len),(None,max_len),(None,max_len)])\n","\n","with redirect_stdout(sys.stderr) :\n","   model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"KbLdNlnSBP9_"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/10\n","170/170 [==============================] - 83s 449ms/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 0.0086 - val_accuracy: 0.9972\n","Epoch 2/10\n","170/170 [==============================] - 50s 293ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0058 - val_accuracy: 0.9983\n","Epoch 3/10\n","170/170 [==============================] - 46s 272ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0059 - val_accuracy: 0.9984\n","Epoch 4/10\n","170/170 [==============================] - 46s 269ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0060 - val_accuracy: 0.9984\n","Epoch 5/10\n","170/170 [==============================] - 42s 249ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0062 - val_accuracy: 0.9984\n","Epoch 6/10\n","170/170 [==============================] - 46s 270ms/step - loss: 8.5694e-04 - accuracy: 0.9998 - val_loss: 0.0061 - val_accuracy: 0.9985\n","Epoch 7/10\n","170/170 [==============================] - 44s 260ms/step - loss: 6.1789e-04 - accuracy: 0.9998 - val_loss: 0.0067 - val_accuracy: 0.9984\n","Epoch 8/10\n","170/170 [==============================] - 43s 250ms/step - loss: 5.2807e-04 - accuracy: 0.9998 - val_loss: 0.0063 - val_accuracy: 0.9986\n","Epoch 9/10\n","170/170 [==============================] - 43s 253ms/step - loss: 3.5368e-04 - accuracy: 0.9999 - val_loss: 0.0080 - val_accuracy: 0.9983\n","Epoch 10/10\n","170/170 [==============================] - 43s 255ms/step - loss: 4.1218e-04 - accuracy: 0.9999 - val_loss: 0.0069 - val_accuracy: 0.9986\n"]}],"source":["## --------- MAIN PROGRAM -----------\n","## --\n","## -- Usage:  train.py ../data/Train ../data/Devel  modelname\n","## --\n","\n","# train model\n","with redirect_stdout(sys.stderr) :\n","   #model.fit([Xt,Xts,Xtp], Yt, batch_size=32, epochs=10, validation_data=([Xv,Xvs,Xvp],Yv), verbose=1)\n","   #model.fit([Xt,Xts,Xtp,Xtlc], Yt, batch_size=32, epochs=10, validation_data=([Xv,Xvs,Xvp,Xvlc],Yv), verbose=1)\n","   #model.fit([Xt,Xts,Xtp,Xtlc,Xtpos], Yt, batch_size=32, epochs=10, validation_data=([Xv,Xvs,Xvp,Xvlc,Xvpos],Yv), verbose=1)\n","   #model.fit([Xt,Xts,Xtp,Xtpos], Yt, batch_size=32, epochs=10, validation_data=([Xv,Xvs,Xvp,Xvpos],Yv), verbose=1)\n","   #model.fit([Xt,Xts,Xtp,Xtpos,Xtlen], Yt, batch_size=32, epochs=10, validation_data=([Xv,Xvs,Xvp,Xvpos,Xvlen],Yv), verbose=1)\n","   #model.fit([Xt,Xts,Xtp,Xtpos,Xtlen,Xtpct,Xtcap], Yt, batch_size=32, epochs=10, validation_data=([Xv,Xvs,Xvp,Xvpos,Xvlen,Xvpct,Xvcap],Yv), verbose=1)\n","   #model.fit([Xt,Xts,Xtp,Xtpos,Xtlen,Xtcap], Yt, batch_size=32, epochs=10, validation_data=([Xv,Xvs,Xvp,Xvpos,Xvlen,Xvcap],Yv), verbose=1)\n","   model.fit([Xt,Xts,Xtp,Xts2,Xtp2,Xtpos,Xtlen,Xtpct,Xtcap], Yt, batch_size=32, epochs=10, validation_data=([Xv,Xvs,Xvp,Xvs2,Xvp2,Xvpos,Xvlen,Xvpct,Xvcap],Yv), verbose=1)\n","\n","\n","# save model and indexs\n","model.save(modelname)\n","#codes.save(modelname)\n","#save_model_and_indexs(model, idx, modelname)"]},{"cell_type":"markdown","metadata":{"id":"aJvfrsbOID0K"},"source":["# Predict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CTRj3WR4IGkU"},"outputs":[],"source":["#import sys\n","import evaluator"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YcVCJho6z7x1"},"outputs":[],"source":["def output_entities(data, preds, outfile) :\n","\n","   outf = open(outfile, 'w')\n","   for sid,tags in zip(data.sentence_ids(),preds) :\n","      inside = False\n","      for k in range(0,min(len(data.get_sentence(sid)),codes.maxlen)) :\n","         y = tags[k]\n","         token = data.get_sentence(sid)[k]\n","\n","         if (y[0]==\"B\") :\n","             entity_form = token['form']\n","             entity_start = token['start']\n","             entity_end = token['end']\n","             entity_type = y[2:]\n","             inside = True\n","         elif (y[0]==\"I\" and inside) :\n","             entity_form += \" \"+token['form']\n","             entity_end = token['end']\n","         elif (y[0]==\"O\" and inside) :\n","             print(sid, str(entity_start)+\"-\"+str(entity_end), entity_form, entity_type, sep=\"|\", file=outf)\n","             inside = False\n","\n","      if inside : print(sid, str(entity_start)+\"-\"+str(entity_end), entity_form, entity_type, sep=\"|\", file=outf)\n","\n","   outf.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CnQTgWHLI47N"},"outputs":[],"source":["## --------- Evaluator -----------\n","def evaluation(datadir,outfile) :\n","   evaluator.evaluate(\"NER\", datadir, outfile)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KJCvMcM-I7fi"},"outputs":[{"name":"stdout","output_type":"stream","text":["45/45 [==============================] - 4s 72ms/step\n","                   tp\t  fp\t  fn\t#pred\t#exp\tP\tR\tF1\n","------------------------------------------------------------------------------\n","brand             277\t  32\t  97\t 309\t 374\t89.6%\t74.1%\t81.1%\n","drug             1682\t 107\t 224\t1789\t1906\t94.0%\t88.2%\t91.0%\n","drug_n             10\t  10\t  35\t  20\t  45\t50.0%\t22.2%\t30.8%\n","group             560\t  82\t 127\t 642\t 687\t87.2%\t81.5%\t84.3%\n","------------------------------------------------------------------------------\n","M.avg            -\t-\t-\t-\t-\t80.2%\t66.5%\t71.8%\n","------------------------------------------------------------------------------\n","m.avg            2529\t 231\t 483\t2760\t3012\t91.6%\t84.0%\t87.6%\n","m.avg(no class)  2590\t 170\t 422\t2760\t3012\t93.8%\t86.0%\t89.7%\n"]}],"source":["## --------- MAIN PROGRAM -----------\n","## --\n","## -- Usage:  baseline-NER.py target-dir\n","## --\n","## -- Extracts Drug NE from all XML files in target-dir\n","## --\n","\n","datadir = validationdir\n","\n","testdata = Dataset(datadir)\n","\n","#[X,Xs,Xp] = codes.encode_words(testdata)\n","#[X,Xs,Xp,Xlc] = codes.encode_words(testdata)\n","#[X,Xs,Xp,Xlc,Xpos] = codes.encode_words(testdata)\n","#[X,Xs,Xp,Xpos] = codes.encode_words(testdata)\n","#[X,Xs,Xp,Xpos,Xlen] = codes.encode_words(testdata)\n","#[X,Xs,Xp,Xpos,Xlen,Xpct] = codes.encode_words(testdata)\n","#[X,Xs,Xp,Xpos,Xlen,Xpct,Xcap] = codes.encode_words(testdata)\n","#[X,Xs,Xp,Xpos,Xlen,Xcap] = codes.encode_words(testdata)\n","[X,Xs,Xp,Xs2,Xp2,Xpos,Xlen,Xpct,Xcap] = codes.encode_words(testdata)\n","\n","\n","#Y = model.predict([X,Xs,Xp])\n","#Y = model.predict([X,Xs,Xp,Xlc])\n","#Y = model.predict([X,Xs,Xp,Xlc,Xpos])\n","#Y = model.predict([X,Xs,Xp,Xpos])\n","#Y = model.predict([X,Xs,Xp,Xpos,Xlen])\n","#Y = model.predict([X,Xs,Xp,Xpos,Xlen,Xpct])\n","#Y = model.predict([X,Xs,Xp,Xpos,Xlen,Xpct,Xcap])\n","#Y = model.predict([X,Xs,Xp,Xpos,Xlen,Xcap])\n","Y = model.predict([X,Xs,Xp,Xs2,Xp2,Xpos,Xlen,Xpct,Xcap])\n","\n","\n","Y = [[codes.idx2label(np.argmax(w)) for w in s] for s in Y]\n","\n","# extract entities\n","output_entities(testdata, Y, outfile)\n","\n","# evaluate\n","evaluation(datadir,outfile)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","provenance":[{"file_id":"1nmnoFCagwMwzL_f05XQGehDH7UtRH3nI","timestamp":1714490361401}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}